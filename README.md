# Chinese-BELLE-LoRA-Tuning
ä½¿ç”¨LoRAå¯¹BELLEå‘å¸ƒçš„BELLE-7B-2Mè¿›è¡Œå¾®è°ƒã€‚æ•´ä½“çš„ç»“æž„éžå¸¸ç®€å•ï¼Œæž„é€ å¥½ç›¸åº”æ ¼å¼çš„æ•°æ®åŽå°±å¯ä»¥å¼€å§‹è®­ç»ƒã€‚

BELLE-7B-2Mä¸‹è½½åœ°å€ï¼š[BelleGroup/BELLE-7B-2M at main (huggingface.co)](https://huggingface.co/BelleGroup/BELLE-7B-2M/tree/main)

è®­ç»ƒå¥½çš„å®žä½“è¯†åˆ«LoRAæƒé‡å·²ç»ä½äºŽcheckpointä¸‹ã€‚

# ä¾èµ–

linuxæ“ä½œç³»ç»Ÿä¸ºUbantuï¼ŒGPUä¸ºA40-48Gæ˜¾å­˜ã€‚

```python
mpi4py
transformers==4.28.1
peft==0.3.0
icetk
deepspeed==0.9.2
accelerate
cpm_kernels
sentencepiece==0.1.99
peft=0.3.0
torch=2.0.0 
```

# è¯´æ˜Ž

## ç›®å½•ç»“æž„

```python
--checkpointï¼šä¿å­˜æ¨¡åž‹
----msraï¼šæ•°æ®é›†åç§°
--------train_deepspeed
------------adapter_model
----------------adapter_config.json
----------------adapter_model.bin
----------------train_args.json
--------train_trainer
------------adapter_model
----------------adapter_config.json
----------------adapter_model.bin
----------------train_args.json
--model_hubï¼šé¢„è®­ç»ƒæ¨¡åž‹
----BEELE-7B-2Mï¼šé¢„è®­ç»ƒæ¨¡åž‹ä½ç½®
--dataï¼šæ•°æ®
----msraï¼šæ•°æ®é›†åç§°
--------instruct_dataï¼šæŒ‡ä»¤æ•°æ®
------------dev.txt
------------train.txt
--------ori_dataï¼šåŽŸå§‹æ•°æ®
--chat_ner.pyï¼šé—²èŠ
--train_deepspeed.pyï¼šä½¿ç”¨åŽŸç”Ÿdeepspeedè®­ç»ƒ
--train_trainer.pyï¼š ä½¿ç”¨transformersçš„Trainerè¿›è¡Œè®­ç»ƒ
--test.pyï¼šæµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡åž‹
--predict.pyï¼šé¢„æµ‹
--process.pyï¼šå¤„ç†æ•°æ®ä¸ºinstruct_data
--dataset.pyï¼šåŠ è½½æ•°æ®ä¸ºç›¸åº”çš„æ ¼å¼
--deepspeed.jsonï¼šdeepspeedé…ç½®æ–‡ä»¶ï¼Œç”¨äºŽtrasnformersçš„Trainer
--config_utils.pyï¼šç”¨äºŽç”¨å­—å…¸å®šä¹‰é…ç½®ï¼Œå¹¶æŽ¥æ”¶å‘½ä»¤è¡Œå‚æ•°
```

## æ•°æ®æ ¼å¼

è¿™é‡Œæˆ‘ä»¬ä»¥å‘½åå®žä½“è¯†åˆ«ä»»åŠ¡ä¸ºä¾‹ï¼Œæ•°æ®åœ¨data/msraä¸‹ï¼Œå…¶ä¸­ori_dataä¸ºåŽŸå§‹æ•°æ®,instruct_dataä¸ºå¤„ç†åŽçš„æ•°æ®ï¼Œæ•°æ®æ ¼å¼ä¸ºä¸€æ¡ä¸€ä¸ªæ ·æœ¬ï¼Œå…·ä½“æ˜¯ï¼š

```python
{"instruct": "ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå®žä½“è¯†åˆ«æ¨¡åž‹ï¼Œä½ éœ€è¦æå–æ–‡æœ¬é‡Œé¢çš„äººåã€åœ°åã€æœºæž„åï¼Œå¦‚æžœå­˜åœ¨ç»“æžœï¼Œè¿”å›ž'å®žä½“_å®žä½“ç±»åž‹'ï¼Œä¸åŒå®žä½“é—´ç”¨\nåˆ†éš”ã€‚å¦‚æžœæ²¡æœ‰ç»“æžœï¼Œå›žç­”'æ²¡æœ‰'ã€‚", "query": "æ–‡æœ¬ï¼šå› æœ‰å…³æ—¥å¯‡åœ¨äº¬æŽ å¤ºæ–‡ç‰©è¯¦æƒ…ï¼Œè—ç•Œè¾ƒä¸ºé‡è§†ï¼Œä¹Ÿæ˜¯æˆ‘ä»¬æ”¶è—åŒ—äº¬å²æ–™ä¸­çš„è¦ä»¶ä¹‹ä¸€ã€‚", "answer": "æ—¥_åœ°å\näº¬_åœ°å\nåŒ—äº¬_åœ°å"}
```

å¯ä»¥æŒ‰ç…§è‡ªå·±çš„ä»»åŠ¡è‡ªè¡Œæž„å»ºã€‚

## ä¸€èˆ¬è¿‡ç¨‹

1ã€dataä¸‹æ–°å»ºæ•°æ®é›†ï¼Œç”¨process.pyå¤„ç†æ•°æ®ä¸ºinstruct_dataä¸‹çš„æ•°æ®ã€‚

2ã€è¿™é‡Œä½¿ç”¨train_trainer.pyè¿›è¡Œè®­ç»ƒï¼Œä¸ºäº†èƒ½å¤Ÿè®©transformersçš„Traineråœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ä¿å­˜loraæƒé‡ï¼Œå¯¹Trainerè¿›è¡Œç›¸åº”çš„ä¿®æ”¹ï¼Œå‚è€ƒï¼šhttps://github.com/huggingface/peft/issues/96 ã€‚å› ä¸ºæœ‰äº†config_utils.pyï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å­—å…¸é‡Œé¢å®šä¹‰ç›¸å…³å‚æ•°ï¼Œç„¶åŽå¯ä»¥åœ¨å‘½ä»¤è¡Œä¿®æ”¹æ¡‰æ ‘çš„å€¼ï¼ˆåµŒå¥—å‚æ•°ä¹‹é—´ç”¨_åˆ†éš”ï¼‰ã€‚

```python
args = {
    "data_name": "msra",  # æ•°æ®é›†åç§°
    "model_dir": "/root/autodl-tmp/chatglm-6b/",  # chatglm-6båœ°å€ï¼Œä¿®æ”¹ä¸ºè‡ªå·±çš„è·¯å¾„
    "lora_r": 8,  # loraå‚æ•°
    "max_source_length": 128,  # instruct+queryçš„æœ€å¤§é•¿åº¦
    "max_target_length": 32,  # answerçš„æœ€å¤§é•¿åº¦
    "instruct_column": "instruct",  # instructåˆ—å
    "query_column": "query",  # queryåˆ—å
    "response_column": "answer",  # answeråˆ—å
    "train_path": "data/msra/instruct_data/train.txt", # è®­ç»ƒæ•°æ®ï¼Œä¿®æ”¹ä¸ºè‡ªå·±æ•°æ®
    "dev_path": "data/msra/instruct_data/dev.txt",  # æµ‹è¯•æ•°æ®ï¼Œä¿®æ”¹ä¸ºè‡ªå·±æ•°æ®
    "ignore_pad_token_for_loss": True,  # é»˜è®¤å°±å¥½
    "train_batch_size": 12,  # è®­ç»ƒbatch_size
    "gradient_accumulation_steps": 1,  # é»˜è®¤å°±å¥½
    "save_dir": "/root/autodl-tmp/msra_trainer/",  # ä¿å­˜æ¨¡åž‹ä½ç½®ï¼Œä¿®æ”¹ä¸ºè‡ªå·±çš„è·¯å¾„
    "num_train_epochs": 1,  # è®­ç»ƒepoch
    "local_rank": -1,  # deepspeedæ‰€éœ€ï¼Œé»˜è®¤å°±å¥½
    "log_steps": 10,  # å¤šå°‘æ­¥æ‰“å°ä¸€æ¬¡ç»“æžœ
    "save_steps": 50,  # å¤šå°‘æ­¥ä¿å­˜ä¸€æ¬¡æ¨¡åž‹
    "deepspeed_json_path": "deepspeed.json" # deepspeedé…ç½®
}
```

éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒTrainerä¸­ä½¿ç”¨deepspeedè¦ä¿æŒdeepspeedå®šä¹‰çš„å‚æ•°å’ŒTraineré‡Œé¢å‚æ•°ä¿æŒä¸€è‡´ï¼Œæ¯”å¦‚ï¼šdeepspeed.jsonï¼š

```python
{
  "train_micro_batch_size_per_gpu": 12,
  "optimizer": {
    "type": "Adam",
    "params": {
      "lr": 1e-05,
      "betas": [
        0.9,
        0.95
      ],
      "eps": 1e-08,
      "weight_decay": 0.0005
    }
  },
  "fp16": {
    "enabled": true
  },
  "zero_optimization": {
    "stage": 1,
    "offload_optimizer": {
      "device": "cpu",
      "pin_memory": true
    },
    "allgather_partitions": true,
    "allgather_bucket_size": 200000000.0,
    "overlap_comm": true,
    "reduce_scatter": true,
    "reduce_bucket_size": 200000000.0,
    "contiguous_gradients": true
  }
}
```

- train_micro_batch_size_per_gpuå’Œper_device_train_batch_size
- lrå’Œlearning_rate
- betasé‡Œé¢å’Œadam_beta1ã€adam_beta2
- weight_decayå’Œweight_decay
- fp16å’Œfp16

é»˜è®¤çš„è¯ä¸ç”¨ä¿®æ”¹è¿™äº›ã€‚

## è®­ç»ƒ

```python
deeepspeed train_deepspeed.py æˆ–è€… deepspeed train_trainer.py
```

## æµ‹è¯•

ä¿®æ”¹data_nameï¼Œè¿è¡Œï¼š`python test.py`

```python
é¢„æµ‹ï¼š ['èŽ«é«˜çªŸ_åœ°å\næ•¦ç…Œ__åœ°å\n', 'æ—¶åŸŽå‡ºç‰ˆç¤¾_æœºæž„å\n', 'ä¸­å›½_åœ°å\nä¸œäº¬å›½é™…æ³•å­¦ä¼š_æœºæž„å\n', 'åº„_äººå\nåº„__äººå\nåº„å‘¨_äººå\n', 'çŽ‰å³°_åœ°å\né‡åº†_åœ°å\n', 'è¥¿æŸå¡_åœ°å\n', 'æ²¡æœ‰_åœ°å\nä¸­å›½å…±äº§å…š_æœºæž„å\n', 'å®é¡¶å±±_åœ°å\nä¸ƒå®—å²æœºæž„\n', 'æ·±_åœ°å\n', 'ç‘žå£«_åœ°å\nè¥¿ç­ç‰™_åœ°å\næ¯”åˆ©æ—¶_åœ°å\nä¸¹éº¦_åœ°å\n', 'å·«å³¡_åœ°å\n', 'å«ç”Ÿéƒ¨_æœºæž„å\né»„é»„éª…å¸‚ä¸­åŒ»ç²¾ç¥žç—…ä¸“ç§‘åŒ»é™¢_æœºæž„å\n', 'äº¬æ²ªé«˜é€Ÿé“è·¯_åœ°å\n', 'ä¸­å›½_åœ°å\n', 'è¥¿æŸå¡_åœ°å\né˜Žä¼šå¼º_äººå\nçŽ‹äºŒåˆš_äººå\nåº“åŠ›è¾‰_äººå\né˜Žä¸œéœž_äººå\né˜Žæ˜Žæ˜Ž_äººå\né˜Žé•¿æ˜Ž_äººå\n', 'ä¸œæ–¹ä¸œæ–¹è‰ºæœ¯ã€‹æ‚å¿—_æœºæž„å\nè¶Šç§€_æœºæž„å\n', 'æ²¡æœ‰_åœ°å\n', 'èš©å°¤å¯¨_åœ°å\né¾™çŽ‹å¡˜_åœ°å\n', 'å®‹ç¥žå®—_äººå\næ¨_æœºæž„å\næ¨æ¬¡å…¬_äººå\n', 'æ•¦ç…Œ_åœ°å\nèŽ«é«˜çªŸ_åœ°å\n']

çœŸå®žï¼š ['èŽ«é«˜çªŸ_åœ°å\næ•¦ç…ŒåŸŽ_åœ°å', 'èŠ±åŸŽå‡ºç‰ˆç¤¾_æœºæž„å', 'ä¸­å›½_åœ°å\nä¸œäº¬å›½é™…æ³•å­¦ä¼š_æœºæž„å', 'ç¥_äººå\nåº„å­_äººå\nåº„å‘¨_äººå', 'çŽ‰å³°_åœ°å\né‡åº†_åœ°å', 'è¥¿æŸå¡_åœ°å', 'ä¸­å›½_åœ°å\nä¸­å›½å…±äº§å…š_æœºæž„å', 'å®é¡¶å±±_åœ°å\nå¯†å®—_äººå', 'æ·±_åœ°å', 'ç‘žå£«_åœ°å\nè¥¿ç­ç‰™_åœ°å\næ¯”åˆ©æ—¶_åœ°å\nä¸¹éº¦_åœ°å', 'å·«å³¡_åœ°å', 'å«ç”Ÿéƒ¨_æœºæž„å\næ²³åŒ—é»„éª…å¸‚ä¸­åŒ»ç²¾ç¥žç—…ä¸“ç§‘åŒ»é™¢_æœºæž„å', 'äº¬æ²ªé«˜é€Ÿé“è·¯_åœ°å', 'ä¸­å›½_åœ°å', 'è¥¿æŸå¡æ‘_åœ°å\né˜Žä¼šå¼º_äººå\nçŽ‹äºŒåˆš_äººå\nåˆ˜åŠ›è¾‰_äººå\né˜Žä¸œéœž_äººå\né˜Žæ˜Žæ˜Ž_äººå\né˜Žé•¿æ˜Ž_äººå', 'ã€Šä¸œæ–¹è‰ºæœ¯ã€‹æ‚å¿—_æœºæž„å\nè¶Šç§€_æœºæž„å', 'çºªå¿µé¦†_åœ°å', 'èš©å°¤å¯¨_åœ°å\né¾™çŽ‹å¡˜æ‘_åœ°å', 'å®‹ç¥žå®—_äººå\nç¤¼éƒ¨_æœºæž„å\næ¨æ¬¡å…¬_äººå', 'æ•¦ç…Œ_åœ°å\nèŽ«é«˜çªŸ_åœ°å']
```

## é¢„æµ‹

ä¿®æ”¹data_nameï¼Œè¿è¡Œï¼š`python predict.py`

```python
æ–‡æœ¬ >>>  "ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå®žä½“è¯†åˆ«æ¨¡åž‹ï¼Œä½ éœ€è¦æå–æ–‡æœ¬é‡Œé¢çš„äººåã€åœ°åã€æœºæž„åï¼Œå¦‚æžœå­˜åœ¨ç»“æžœï¼Œè¿”å›ž'å®žä½“_å®žä½“ç±»åž‹'ï¼Œä¸åŒå®žä½“é—´ç”¨\nåˆ†éš”ã€‚å¦‚æžœæ²¡æœ‰ç»“æžœï¼Œå›žç­”'æ²¡æœ‰'ã€‚æ–‡æœ¬ï¼šæˆ‘ä»¬æ˜¯å—åˆ°éƒ‘æŒ¯é“Žå…ˆç”Ÿã€é˜¿è‹±å…ˆç”Ÿè‘—ä½œçš„å¯ç¤ºï¼Œä»Žä¸ªäººæ¡ä»¶å‡ºå‘ï¼Œçž„å‡†çŽ°ä»£å‡ºç‰ˆå²ç ”ç©¶çš„ç©ºç™½ï¼Œé‡ç‚¹é›†è—è§£æ”¾åŒºã€å›½æ°‘å…šæ¯ç¦å‡ºç‰ˆç‰©ã€‚"
é¢„æµ‹ >>>  éƒ‘æŒ¯é“Ž_äººå
é˜¿è‹±_äººå
è§£æ”¾_æœºæž„å

çœŸå®ž >>>  éƒ‘æŒ¯é“Ž_äººå
é˜¿è‹±_äººå
å›½æ°‘å…š_æœºæž„å
æ–‡æœ¬ >>>  "ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå®žä½“è¯†åˆ«æ¨¡åž‹ï¼Œä½ éœ€è¦æå–æ–‡æœ¬é‡Œé¢çš„äººåã€åœ°åã€æœºæž„åï¼Œå¦‚æžœå­˜åœ¨ç»“æžœï¼Œè¿”å›ž'å®žä½“_å®žä½“ç±»åž‹'ï¼Œä¸åŒå®žä½“é—´ç”¨\nåˆ†éš”ã€‚å¦‚æžœæ²¡æœ‰ç»“æžœï¼Œå›žç­”'æ²¡æœ‰'ã€‚æ–‡æœ¬ï¼šåŽ»å¹´ï¼Œæˆ‘ä»¬åˆè¢«è¯„ä¸ºâ€œåŒ—äº¬å¸‚é¦–å±Šå®¶åº­è—ä¹¦çŠ¶å…ƒæ˜Žæ˜Ÿæˆ·â€ã€‚"
é¢„æµ‹ >>>  åŒ—äº¬å¸‚_åœ°å

çœŸå®ž >>>  åŒ—äº¬å¸‚_åœ°å
æ–‡æœ¬ >>>  "ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå®žä½“è¯†åˆ«æ¨¡åž‹ï¼Œä½ éœ€è¦æå–æ–‡æœ¬é‡Œé¢çš„äººåã€åœ°åã€æœºæž„åï¼Œå¦‚æžœå­˜åœ¨ç»“æžœï¼Œè¿”å›ž'å®žä½“_å®žä½“ç±»åž‹'ï¼Œä¸åŒå®žä½“é—´ç”¨\nåˆ†éš”ã€‚å¦‚æžœæ²¡æœ‰ç»“æžœï¼Œå›žç­”'æ²¡æœ‰'ã€‚æ–‡æœ¬ï¼šè—ä¹¦å®¶ã€ä½œå®¶å§œå¾·æ˜Žå…ˆç”Ÿåœ¨1997å¹´å‡ºç‰ˆçš„ä¹¦è¯ä¸“é›†ã€Šæ–‡æž—æžå¶ã€‹ä¸­ä»¥â€œçˆ±ä¹¦çš„æœ‹å‹â€ä¸ºé¢˜ï¼Œè¯¦ç»†ä»‹ç»äº†æˆ‘ä»¬å¤«å¦‡çš„è—å“åŠä¸‰å£ä¹‹å®¶ä»¥ä¹¦ä¸ºå‹ã€å¥½ä¹æ¸…è´«çš„é€¸é—»è¶£äº‹ã€‚"
é¢„æµ‹ >>>  å§œå¾·æ˜Ž_äººå

çœŸå®ž >>>  å§œå¾·æ˜Ž_äººå
```

## é—²èŠ

ä¿®æ”¹data_nameï¼Œè¿è¡Œï¼š`python chat_ner.py --model_name "bloom" --base_model "./model_hub/BELLE-7B-2M" --tokenizer_path "./model_hub/BELLE-7B-2M" --lora_model "./checkpoint/msra/train_trainer/adapter_model" --with_prompt --interactive`

````python
åŠ è½½æ¨¡åž‹è€—æ—¶ï¼š5.13695338567098åˆ†é’Ÿ
loading peft model
Start inference with instruction mode.
=====================================================================================
+ å½“å‰ä½¿ç”¨çš„æ¨¡åž‹æ˜¯ï¼šbloom
-------------------------------------------------------------------------------------
+ è¯¥æ¨¡å¼ä¸‹ä»…æ”¯æŒå•è½®é—®ç­”ï¼Œæ— å¤šè½®å¯¹è¯èƒ½åŠ›ã€‚
+ å¦‚æžœæ˜¯llamaæˆ–è€…alpacaæ¨¡åž‹ï¼Œå¦‚è¦è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œè¯·ä½¿ç”¨llama.cppæˆ–llamachatå·¥å…·ã€‚
=====================================================================================
Input:ä½ å¥½

Assistant: 
ä½ å¥½ï¼Œæœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„å—ï¼Ÿ

Input:ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå®žä½“è¯†åˆ«æ¨¡åž‹ï¼Œä½ éœ€è¦æå–æ–‡æœ¬é‡Œé¢çš„äººåã€åœ°åã€æœºæž„åï¼Œå¦‚æžœå­˜åœ¨ç»“æžœï¼Œè¿”å›ž'å®žä½“_å®žä½“ç±»åž‹'ï¼Œä¸åŒå®žä½“é—´ç”¨\nåˆ†éš”ã€‚å¦‚æžœæ²¡æœ‰ç»“æžœï¼Œå›žç­”'æ²¡æœ‰'ã€‚æ–‡æœ¬ï¼šæˆ‘ä»¬æ˜¯å—åˆ°éƒ‘æŒ¯é“Žå…ˆç”Ÿã€é˜¿è‹±å…ˆç”Ÿè‘—ä½œçš„å¯ç¤ºï¼Œä»Žä¸ªäººæ¡ä»¶å‡ºå‘ï¼Œçž„å‡†çŽ°ä»£å‡ºç‰ˆå²ç ”ç©¶çš„ç©ºç™½ï¼Œé‡ç‚¹é›†è—è§£æ”¾åŒºã€å›½æ°‘å…šæ¯ç¦å‡ºç‰ˆç‰©ã€‚

Assistant: 
éƒ‘æŒ¯é“Ž_äººå
é˜¿è‹±_äººå
````

åŽŸå§‹æ¨¡åž‹ä¹Ÿå¹¶æ²¡æœ‰é€€åŒ–ã€‚

## æŠ¥é”™è§£å†³

- å®‰è£…mpi4pyæŠ¥é”™

```python
sudo apt-get update
sudo apt-get install openmpi-bin libopenmpi-dev
pip install mpi4py
```

# è¡¥å……

- **æ€Žä¹ˆè®­ç»ƒè‡ªå·±çš„æ•°æ®ï¼Ÿ**
	æŒ‰ç…§instruct_dataä¸‹çš„æ•°æ®ç»“æž„æž„é€ æ•°æ®ï¼Œå®šä¹‰å¥½ç›¸å…³å‚æ•°è¿è¡Œå³å¯ã€‚
- **æ€Žä¹ˆè¿›è¡Œé¢„æµ‹ï¼Ÿ**
	åœ¨test.pyä¸­ï¼Œé¢„æµ‹æ—¶å¯æ ¹æ®è‡ªå·±çš„ä»»åŠ¡è¿›è¡Œè§£ç ã€‚
- **ä¸ºä»€ä¹ˆä¸è¿›è¡Œè¯„ä»·æŒ‡æ ‡çš„è®¡ç®—ï¼Ÿ**
	åªæ˜¯ä½œäº†åˆæ­¥çš„è®­ç»ƒï¼Œéš¾å…æ•ˆæžœä¸å¤ªå¥½å°±ä¸è¿›è¡Œè¯„ä»·æŒ‡æ ‡çš„è®¡ç®—äº†ï¼Œå¯ä»¥åœ¨test.pyé‡Œé¢è‡ªè¡Œå®šä¹‰ã€‚

# å‚è€ƒ

> [liucongg/ChatGLM-Finetuning: åŸºäºŽChatGLM-6Bæ¨¡åž‹ï¼Œè¿›è¡Œä¸‹æ¸¸å…·ä½“ä»»åŠ¡å¾®è°ƒï¼Œæ¶‰åŠFreezeã€Loraã€P-tuningç­‰ (github.com)](https://github.com/liucongg/ChatGLM-Finetuning)
>
> [THUDM/ChatGLM-6B: ChatGLM-6B: An Open Bilingual Dialogue Language Model | å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡åž‹ (github.com)](https://github.com/THUDM/ChatGLM-6B/projects?query=is%3Aopen)
>
> [huggingface/peft: ðŸ¤— PEFT: State-of-the-art Parameter-Efficient Fine-Tuning. (github.com)](https://github.com/huggingface/peft)
>
> https://github.com/LianjiaTech/BELLE/
